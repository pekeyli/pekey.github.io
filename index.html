<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    
<meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>


<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">















  <link rel="alternate" href="/default" title="Pekey">




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=2.6.0" />



<link rel="canonical" href="http://yoursite.com/"/>


<link rel="stylesheet" type="text/css" href="/css/style.css?v=2.6.0" />






  



  <script id="baidu_push">
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>









    <title> Pekey </title>
  </head>

  <body><div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/." class="logo">Pekey</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>

<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    
      <a href="/">
        <li class="mobile-menu-item">
          
          
            首页
          
        </li>
      </a>
    
      <a href="/archives/">
        <li class="mobile-menu-item">
          
          
            归档
          
        </li>
      </a>
    
  </ul>
</nav>

    <div class="container" id="mobile-panel">
      <header id="header" class="header"><div class="logo-wrapper">
  <a href="/." class="logo">Pekey</a>
</div>

<nav class="site-navbar">
  
    <ul id="menu" class="menu">
      
        <li class="menu-item">
          <a class="menu-item-link" href="/">
            
            
              首页
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/archives/">
            
            
              归档
            
          </a>
        </li>
      
    </ul>
  
</nav>

      </header>

      <main id="main" class="main">
        <div class="content-wrapper">
          <div id="content" class="content">
            
  <section id="posts" class="posts">
    
      
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          <a class="post-link" href="/2018/04/17/Spark-Java-API/">Spark Java API</a>
        
      </h1>

      <div class="post-meta">
        <span class="post-time">
          2018-04-17
        </span>
        
        
      </div>
    </header>

    
    

    <div class="post-content">
      
        
        

        
          <h3 id="RDD如何创建"><a href="#RDD如何创建" class="headerlink" title="RDD如何创建"></a>RDD如何创建</h3><p>　　　　<br>首先创建JavaSparkContext对象实例sc</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">JavaSparkContext  sc = new JavaSparkContext(&quot;local&quot;,&quot;SparkTest&quot;);</span><br></pre></td></tr></table></figure>
<p>接受2个参数：<br>第一个参数表示运行方式（local、yarn-client、yarn-standalone等）<br>第二个参数表示应用名字</p>
<blockquote>
<p>直接从集合转化 <code>sc.parallelize(List(1,2,3,4,5,6,7,8,9,10))</code><br>从HDFS文件转化  <code>sc.textFile(&quot;hdfs://&quot;)</code><br>从本地文件转化  <code>sc.textFile(&quot;file:/&quot;)</code></p>
</blockquote>
<p>下面例子中list2就是根据data2List生成的一个RDD</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">List&lt;String&gt; list1 = new ArrayList&lt;String&gt;();</span><br><span class="line">list1.add(&quot;11,12,13,14,15&quot;);</span><br><span class="line">list1.add(&quot;aa,bb,cc,dd,ee&quot;);</span><br><span class="line">JavaRDD&lt;String&gt; list2 = sc.parallelize(list1);</span><br></pre></td></tr></table></figure>
<h3 id="常用算子"><a href="#常用算子" class="headerlink" title="常用算子"></a>常用算子</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">JavaRDD&lt;String []&gt; rdd = list2.map(</span><br><span class="line">    new Function&lt;String, String []&gt;() &#123;</span><br><span class="line">        @Override</span><br><span class="line">        public String [] call(String arg0) throws Exception &#123;</span><br><span class="line">            return arg0.split(&quot;,&quot;);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">);</span><br><span class="line">System.out.println(Util.printAList(rdd.collect()));</span><br></pre></td></tr></table></figure>

        
      
    </div>

    

    

  </article>

    
      
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          <a class="post-link" href="/2018/04/17/Hbase环境搭建/">Hbase环境搭建</a>
        
      </h1>

      <div class="post-meta">
        <span class="post-time">
          2018-04-17
        </span>
        
        
      </div>
    </header>

    
    

    <div class="post-content">
      
        
        

        
          <h3 id="配置过程"><a href="#配置过程" class="headerlink" title="配置过程"></a>配置过程</h3><ul>
<li>hbase-env.sh</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/home/grid/jdk1.7.0_75  </span><br><span class="line">export HBASE_HOME=/home/grid/hbase  </span><br><span class="line">export HBASE_LOG_DIR=/tmp/grid/logs  </span><br><span class="line">export HBASE_MANAGES_ZK=true</span><br></pre></td></tr></table></figure>
<ul>
<li>hbase-site.xml</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;  </span><br><span class="line">    &lt;property&gt;  </span><br><span class="line">        &lt;name&gt;hbase.rootdir&lt;/name&gt; # 设置 hbase 数据库存放数据的目录  </span><br><span class="line">        &lt;value&gt;hdfs://master:9000/hbase&lt;/value&gt;  </span><br><span class="line">    &lt;/property&gt;  </span><br><span class="line"></span><br><span class="line">    &lt;property&gt;  </span><br><span class="line">        &lt;name&gt;hbase.cluster.distributed&lt;/name&gt;  # 打开 hbase 分布模式  </span><br><span class="line">        &lt;value&gt;true&lt;/value&gt;  </span><br><span class="line">    &lt;/property&gt;  </span><br><span class="line"></span><br><span class="line">    &lt;property&gt;  </span><br><span class="line">        &lt;name&gt;hbase.master&lt;/name&gt; # 指定 hbase 集群主控节点  </span><br><span class="line">        &lt;value&gt;master:60000&lt;/value&gt;  </span><br><span class="line">    &lt;/property&gt;  </span><br><span class="line"></span><br><span class="line">    &lt;property&gt;  </span><br><span class="line">        &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;  </span><br><span class="line">        &lt;value&gt;master,slave1,slave2&lt;/value&gt; # 指定 zookeeper 集群节点名 , 因为是由 zookeeper 表决算法决定的  </span><br><span class="line">    &lt;/property&gt;  </span><br><span class="line"></span><br><span class="line">    &lt;property&gt;  </span><br><span class="line">        &lt;name&gt;hbase.zookeeper.property.dataDir&lt;/name&gt; # 指 zookeeper 集群 data 目录  </span><br><span class="line">        &lt;value&gt;/home/grid/hbase/zookeeper&lt;/value&gt;  </span><br><span class="line">    &lt;/property&gt;  </span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>
<ul>
<li>regionservers</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">slave1  </span><br><span class="line">slave2</span><br></pre></td></tr></table></figure>
<h3 id="启动过程"><a href="#启动过程" class="headerlink" title="启动过程"></a>启动过程</h3><ol>
<li><p>启动Hadoop</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$HADOOP_HOME/sbin/start-dfs.sh  </span><br><span class="line">$HADOOP_HOME/sbin/start-yarn.sh</span><br></pre></td></tr></table></figure>
</li>
<li><p>启动Hbase</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$HBASE_HOME/bin/start-hbase.sh</span><br></pre></td></tr></table></figure>
</li>
<li><p>查看hbase启动情况<br>在master上有HQuorumPeer和HMaster进程，在slave1、slave2上有HQuorumPeer和HRegionServer进程</p>
<blockquote>
<p>通过浏览器验证：<a href="http://nodeh1:16010/master-status" target="_blank" rel="noopener">http://nodeh1:16010/master-status</a></p>
</blockquote>
</li>
<li><p>命令行启动</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/home/grid/hbase/bin/hbase shell</span><br></pre></td></tr></table></figure>
</li>
</ol>

        
      
    </div>

    

    

  </article>

    
      
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          <a class="post-link" href="/2018/04/17/Hadoop环境搭建/">Hadoop环境搭建</a>
        
      </h1>

      <div class="post-meta">
        <span class="post-time">
          2018-04-17
        </span>
        
        
      </div>
    </header>

    
    

    <div class="post-content">
      
        
        

        
          <h3 id="配置过程"><a href="#配置过程" class="headerlink" title="配置过程"></a>配置过程</h3><ul>
<li><p>hadoop-env.sh</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/opt/java/jdk1.7.0_80</span><br><span class="line">export HADOOP_PREFIX=/opt/hadoop-2.6.4</span><br></pre></td></tr></table></figure>
</li>
<li><p>core-site.xml</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;fs.defaultFS&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;hdfs://master:9000&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;/opt/hadoop-2.6.4/tmp&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>注意：tmp目录需提前创建</p>
</blockquote>
</li>
<li><p>hdfs-site.xml</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.replication&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;3&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>数据有三个副本</p>
</blockquote>
</li>
<li><p>mapred-site.xml</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;yarn&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>
</li>
<li><p>yarn-env.sh</p>
<blockquote>
<p>增加 JAVA_HOME 配置</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/opt/java/jdk1.7.0_80</span><br></pre></td></tr></table></figure>
</blockquote>
</li>
<li><p>yarn-site.xml</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- Site specific YARN configuration properties --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;nodeh1&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>
</li>
<li><p>slaves</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">master</span><br><span class="line">slave01</span><br><span class="line">slave02</span><br></pre></td></tr></table></figure>
<blockquote>
<p>master 即作为 NameNode 也作为 DataNode。</p>
</blockquote>
</li>
</ul>
<h3 id="启动过程"><a href="#启动过程" class="headerlink" title="启动过程"></a>启动过程</h3><ol>
<li><p>格式化文件系统，在 master 上执行以下命令：</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs namenode -format</span><br></pre></td></tr></table></figure>
</li>
<li><p>启动 NameNode 和 DateNode，执行 <code>start-dfs.sh</code>，使用 jps 命令查看进程。</p>
</li>
<li><p>输入地址：<a href="http://master:50070/" target="_blank" rel="noopener">http://master:50070/</a> 可以查看 NameNode 信息。</p>
</li>
<li><p>启动 ResourceManager 和 NodeManager，运行 <code>start-yarn.sh</code>, 使用 jps 查看  进程</p>
</li>
</ol>
<h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.3.jar wordcount /data/input /data/output/result</span><br></pre></td></tr></table></figure>

        
      
    </div>

    

    

  </article>

    
      
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          <a class="post-link" href="/2018/04/17/Spark环境搭建/">Spark环境搭建</a>
        
      </h1>

      <div class="post-meta">
        <span class="post-time">
          2018-04-17
        </span>
        
        
      </div>
    </header>

    
    

    <div class="post-content">
      
        
        

        
          <h3 id="配置过程"><a href="#配置过程" class="headerlink" title="配置过程"></a>配置过程</h3><p>进入 Spark 安装目录下的 conf 目录， 拷贝 spark-env.sh.template 到 spark-env.sh。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp spark-env.sh.template spark-env.sh</span><br></pre></td></tr></table></figure></p>
<p>编辑 spark-env.sh，在其中添加以下配置信息：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">export SCALA_HOME=/opt/scala-2.11.8</span><br><span class="line">export JAVA_HOME=/opt/java/jdk1.7.0_80</span><br><span class="line">export SPARK_MASTER_IP=192.168.109.137</span><br><span class="line">export SPARK_WORKER_MEMORY=1g</span><br><span class="line">export HADOOP_CONF_DIR=/opt/hadoop-2.6.4/etc/hadoop</span><br></pre></td></tr></table></figure></p>
<p>将 slaves.template 拷贝到 slaves， 编辑其内容为：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">master</span><br><span class="line">slave01</span><br><span class="line">slave02</span><br></pre></td></tr></table></figure></p>
<p>即 master 既是 Master 节点又是 Worker 节点。</p>
<h3 id="启动过程"><a href="#启动过程" class="headerlink" title="启动过程"></a>启动过程</h3><blockquote>
<ol>
<li>运行 start-master.sh，启动Master节点，可以看到master上多了一个新进程Master。</li>
<li>运行 start-slaves.sh，启动所有Worker节点，在 master、slave01和slave02上使用jps命令，可以发现都启动了一个Worker进程</li>
<li>访问 <a href="http://master:8080" target="_blank" rel="noopener">http://master:8080</a>  浏览器查看Spark集群信息。</li>
<li>运行 spark-shell，可以进入Spark的shell控制台</li>
<li>访问 <a href="http://master:4040" target="_blank" rel="noopener">http://master:4040</a>  浏览器访问SparkUI， 可以从SparkUI上查看一些 如环境变量、Job、Executor等信息。</li>
</ol>
</blockquote>
<h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h3><p>计算 π 的近似值<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$SPARK_HOME/bin/run-example SparkPi 2&gt;&amp;1 | grep &quot;Pi is roughly&quot;</span><br></pre></td></tr></table></figure></p>

        
      
    </div>

    

    

  </article>

    
      
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          <a class="post-link" href="/2018/04/17/集群环境搭建过程遇到的问题/">集群环境搭建过程遇到的问题</a>
        
      </h1>

      <div class="post-meta">
        <span class="post-time">
          2018-04-17
        </span>
        
        
      </div>
    </header>

    
    

    <div class="post-content">
      
        
        

        
          <h3 id="MySQL-is-running-but-PID-file-could-not-be-found"><a href="#MySQL-is-running-but-PID-file-could-not-be-found" class="headerlink" title="MySQL is running but PID file could not be found"></a>MySQL is running but PID file could not be found</h3><p>在Linux 中，当你启动或者重启 MySQL 时，报关于 PID file 的错误</p>
<blockquote>
<p>第一步：找到   mysql 中 data 目录下的 mysql-bin.index 文件，然后删除<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">find / -name mysql-bin.index</span><br><span class="line">rm -rf  /phpstudy/data/mysql-bin.index</span><br></pre></td></tr></table></figure></p>
</blockquote>
<blockquote>
<p>第二步：找到 并 kill 所有关于 mysql 或者 mysqld 的进程</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ps -aux | grep mysql</span><br><span class="line">kill 进程号</span><br></pre></td></tr></table></figure>
<p>可以在查看下进程中是否有 mysql 进程，确保 kill 干净，再看看 还有没有 mysql-bin.index文件（进程没杀死之前可能会生成）&lt;有必要&gt;</p>
<blockquote>
<p>命令：  service mysqld status</p>
</blockquote>
<hr>
<h3 id="mysqld：未被识别的服务"><a href="#mysqld：未被识别的服务" class="headerlink" title="mysqld：未被识别的服务"></a>mysqld：未被识别的服务</h3><p>遇到这样的错误，是由于 /etc/init.d/  不存在 mysqld 这个命令（有的人安装完环境后存在，是因为你的安装包中有这样的命令将 mysql.server 文件 copy 到 /etc/init.d/ 下面了）</p>
<blockquote>
<p>1.首先你需要找到 mysql.server 文件，这个 和 mysqld 文件是一模一样的，只不过文件名不相同，执行命令：</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">find  /  -name mysql.server</span><br></pre></td></tr></table></figure>
<blockquote>
<p>2.copy mysql.server 文件到 /etc/init.d/ 目录下，重命名文件为 mysqld，执行命令：</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp  /phpstudy/mysql/support-files/mysql.server  /etc/init.d/mysqld</span><br></pre></td></tr></table></figure>
<blockquote>
<p>然后 再  <code>service mysqld status</code> 这个问题就解决了。</p>
</blockquote>

        
      
    </div>

    

    

  </article>

    
      
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          <a class="post-link" href="/2018/04/16/环境搭建的常用命令/">集群环境搭建的常用命令</a>
        
      </h1>

      <div class="post-meta">
        <span class="post-time">
          2018-04-16
        </span>
        
        
      </div>
    </header>

    
    

    <div class="post-content">
      
        
        

        
          <h4 id="关闭防火墙和SELinux"><a href="#关闭防火墙和SELinux" class="headerlink" title="关闭防火墙和SELinux"></a>关闭防火墙和SELinux</h4><blockquote>
<p><strong>关闭命令：</strong> service iptables stop<br><strong>永久关闭防火墙：</strong> chkconfig iptables off<br><strong>查看防火墙关闭状态:</strong>  service iptables status</p>
</blockquote>
<h4 id="无密码登录"><a href="#无密码登录" class="headerlink" title="无密码登录"></a>无密码登录</h4><blockquote>
<p>ssh-keygen -t rsa<br>cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys<br>chmod 600 ~/.ssh/authorized_keys<br>ssh localhost</p>
</blockquote>
<h4 id="显示文件夹大小并排序"><a href="#显示文件夹大小并排序" class="headerlink" title="显示文件夹大小并排序"></a>显示文件夹大小并排序</h4><blockquote>
<p>du -h –max-depth=1 ./  | sort -n</p>
</blockquote>
<h4 id="将旧版本的jdk升级为新版本"><a href="#将旧版本的jdk升级为新版本" class="headerlink" title="将旧版本的jdk升级为新版本"></a>将旧版本的jdk升级为新版本</h4><blockquote>
<p>sudo update-alternatives –install /usr/bin/java java /opt/soft/jdk/bin/java 300<br>sudo update-alternatives –install /usr/bin/javac javac /opt/soft/jdk/bin/javac 300<br>sudo update-alternatives –config java</p>
</blockquote>
<h4 id="ecilpse访问的权限设置"><a href="#ecilpse访问的权限设置" class="headerlink" title="ecilpse访问的权限设置"></a>ecilpse访问的权限设置</h4><blockquote>
<p>groupadd supergroup # 添加supergroup组<br>useradd -g supergroup hadoop # 添加hadoop用户到supergroup组<br>hadoop fs -chmod 777 /</p>
</blockquote>
<h4 id="查看系统版本"><a href="#查看系统版本" class="headerlink" title="查看系统版本"></a>查看系统版本</h4><blockquote>
<p><strong>其他系列</strong> cat /proc/version<br><strong>redhat系列</strong> cat /etc/redhat-release</p>
</blockquote>
<h4 id="修改hostname"><a href="#修改hostname" class="headerlink" title="修改hostname"></a>修改hostname</h4><blockquote>
<p><strong>centos 6</strong><br>vim /etc/sysconfig/network<br>hostname yourhostname<br><strong>centos 7</strong><br>hostnamectl set-hostname yourhostname</p>
</blockquote>
<h4 id="Spark-上传jar包"><a href="#Spark-上传jar包" class="headerlink" title="Spark 上传jar包"></a>Spark 上传jar包</h4><blockquote>
<p>/opt/moudles/spark-1.6.1/bin/spark-submit –class SparkWordCount sparkStudy.jar  –master=spark://192.168.20.171:7077</p>
</blockquote>
<h4 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h4><blockquote>
<p>chmod -R 777 ./spark</p>
</blockquote>

        
      
    </div>

    

    

  </article>

    
      
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          <a class="post-link" href="/2018/04/11/SpagoBI5.2开发环境搭建/">SpagoBI5.2开发环境搭建</a>
        
      </h1>

      <div class="post-meta">
        <span class="post-time">
          2018-04-11
        </span>
        
        
      </div>
    </header>

    
    

    <div class="post-content">
      
        
        

        
          <p>本文暂不介绍kylin具体的搭建过程，而是将遇到的问题进行了总结，具体的搭建过程可能在后续进行更新。</p>
<hr>
<p>本地运行SpagoBI时需要JDK1.8的运行环境。</p>
<hr>
<p>表图引擎模块的action</p>
<blockquote>
<p>Bichartengine/WEB-INF/conf/commons/actions.xml</p>
</blockquote>
<p>整个项目的Service</p>
<blockquote>
<p>Spagobi-core/src/it/eng/spagobi/wepp/service</p>
</blockquote>
<hr>
<p>导入sql文件出错时</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; SET GLOBAL sql_mode = &apos;&apos;;   </span><br><span class="line">Query OK, 0 rows affected, 1 warning (0.00 sec)   </span><br><span class="line">mysql&gt; commit;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line">mysql&gt; exit;</span><br></pre></td></tr></table></figure>
<hr>
<p>按照从SVN中导出的代码的Server.xml进行修改</p>
<blockquote>
<p>同时修改hibernate.cfg.xml<br>配置数据源 hibernate.cfg.xml (SpagoBI/src/main/resources)</p>
</blockquote>
<p>注意Server.xml中配置数据库时注意大小写</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">&lt;GlobalNamingResources&gt;</span><br><span class="line">    &lt;!-- Editable user database that can also be used by</span><br><span class="line">         UserDatabaseRealm to authenticate users</span><br><span class="line">    --&gt;</span><br><span class="line">    &lt;Resource auth=&quot;Container&quot; description=&quot;User database that can be updated and saved&quot; factory=&quot;org.apache.catalina.users.MemoryUserDatabaseFactory&quot; name=&quot;UserDatabase&quot; pathname=&quot;conf/tomcat-users.xml&quot; type=&quot;org.apache.catalina.UserDatabase”/&gt;</span><br><span class="line"></span><br><span class="line">    &lt;Environment name=&quot;spagobi_resource_path&quot; type=&quot;java.lang.String&quot; value=&quot;C:\progetti\spagobi2.0\workspace\resources&quot;/&gt;</span><br><span class="line">    &lt;Environment name=&quot;spagobi_sso_class&quot; type=&quot;java.lang.String&quot; value=&quot;it.eng.spagobi.services.common.FakeSsoService&quot;/&gt;</span><br><span class="line">    &lt;Environment name=&quot;spagobi_service_url&quot; type=&quot;java.lang.String&quot; value=&quot;http://localhost:8080/SpagoBI&quot;/&gt;    </span><br><span class="line">    &lt;Environment name=&quot;spagobi_host_url&quot; type=&quot;java.lang.String&quot; value=&quot;http://localhost:8080&quot;/&gt;</span><br><span class="line"></span><br><span class="line">    &lt;Resource auth=&quot;Container&quot; factory=&quot;de.myfoo.commonj.work.FooWorkManagerFactory&quot; maxThreads=&quot;5&quot;</span><br><span class="line">          name=&quot;wm/SpagoWorkManager&quot; type=&quot;commonj.work.WorkManager&quot;/&gt;</span><br><span class="line"></span><br><span class="line">    &lt;Resource auth=&quot;Container&quot; driverClassName=&quot;com.mysql.jdbc.Driver&quot;</span><br><span class="line">          maxActive=&quot;20&quot; maxIdle=&quot;10&quot; maxWait=&quot;-1&quot; name=&quot;jdbc/foodmart&quot;</span><br><span class="line">          password=&quot;root&quot; type=&quot;javax.sql.DataSource&quot;</span><br><span class="line">          url=&quot;jdbc:mysql://localhost/foodmart&quot; username=&quot;root&quot;/&gt;          </span><br><span class="line"></span><br><span class="line">    &lt;Resource name=&quot;jdbc/spagobi&quot; auth=&quot;Container&quot;</span><br><span class="line">          type=&quot;javax.sql.DataSource&quot; driverClassName=&quot;com.mysql.jdbc.Driver&quot;</span><br><span class="line">          url=&quot;jdbc:mysql://localhost/spagobi&quot;</span><br><span class="line">          username=&quot;root&quot; password=&quot;root&quot; maxActive=&quot;20&quot; maxIdle=&quot;10&quot;</span><br><span class="line">          maxWait=&quot;-1&quot;/&gt;  </span><br><span class="line"></span><br><span class="line">  &lt;/GlobalNamingResources&gt;</span><br></pre></td></tr></table></figure>
<hr>
<p>虽然代码很多url等都写入了配置文件，但<strong>server.xml</strong>中的<strong>host url</strong>还是需要手动修改</p>
<hr>
<p>记得将符合自己mysql版本的jar包放到tomcat的lib中</p>
<hr>
<blockquote>
<p>Unsupported major.minor version 52.0</p>
</blockquote>
<p>这个错误不要把JRE更换到高版本，更换到高版本会报一个新的15.0错误，没用，而是应该修改<strong>web.xml</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;web-app xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns=&quot;http://java.sun.com/xml/ns/javaee&quot; xmlns:web=&quot;http://java.sun.com/xml/ns/javaee/web-app_2_5.xsd&quot; xsi:schemaLocation=&quot;http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_3_0.xsd&quot; id=&quot;WebApp_ID&quot; version=&quot;3.0&quot; metadata-complete=&quot;true” &gt;</span><br></pre></td></tr></table></figure>
<p>添加一句：metadata-complete=”true” 就搞定了，我猜想由于项目是原来的项目，web.xml是原来项目的，和原来的什么版本可能有冲突，具体的也不清楚了</p>
<hr>
<p>按照src中的whatiftemplate的替换一下，可以修正错误</p>
<hr>
<p>在部署过多项目，如果报内存溢出异常，则需要修改一下tomcat的设置</p>
<blockquote>
<p>-Xms256m -Xmx512m -XX:MaxNewSize=256m -XX:MaxPermSize=256m</p>
</blockquote>
<hr>
<blockquote>
<p>Servlet mapping specifies an unknown servlet name AdapterHTTP</p>
<p>Servlet 2.3 jar not loaded</p>
</blockquote>
<p>在Java Resource 中找到对应jar包，然后exclude<br>不知道是否正确</p>

        
      
    </div>

    

    

  </article>

    
      
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          <a class="post-link" href="/2018/04/11/Kylin2-0环境搭建/">Kylin2.0环境搭建</a>
        
      </h1>

      <div class="post-meta">
        <span class="post-time">
          2018-04-11
        </span>
        
        
      </div>
    </header>

    
    

    <div class="post-content">
      
        
        

        
          <p>本文暂不介绍kylin具体的搭建过程，而是将遇到的问题进行了总结，具体的搭建过程可能在后续进行更新。</p>
<hr>
<p>kylin相关组件启动命令<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ZOOKEEPER_HOME/bin/zkServer.sh start  </span><br><span class="line">$HADOOP_HOME/sbin/start-dfs.sh  </span><br><span class="line">$HADOOP_HOME/sbin/start-yarn.sh  </span><br><span class="line">$HADOOP_HOME/sbin/mr-jobhistory-daemon.sh start historyserver  </span><br><span class="line">service mysqld start  </span><br><span class="line">nohup $HIVE_HOME/bin/hive --service metastore &gt; /tmp/hive_metastore.log 2&gt;&amp;1 &amp;  </span><br><span class="line">$HBASE_HOME/bin/start-hbase.sh</span><br><span class="line">$KYLIN_HOME/bin/kylin.sh start</span><br></pre></td></tr></table></figure></p>
<p>其他命令<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jar cv0f spark-libs.jar -C $KYLIN_HOME/spark/jars/ .</span><br></pre></td></tr></table></figure></p>
<hr>
<p>如出现以下错误</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Failed to load keystore type JKS with pathconf/.keystore due to /home/hadoop/apache-kylin-2.0.0-bin/tomcat/conf/.keystore(没有那个文件或目录)</span><br><span class="line">java.io.FileNotFoundException: /home/hadoop/apache-kylin-2.0.0-bin/tomcat/conf/.keystore(没有那个文件或目录)</span><br><span class="line">       at java.io.FileInputStream.open(Native Method)</span><br></pre></td></tr></table></figure>
<p>则去掉tomcat下的https<br>在kylin内置tomcat的server.xml中里边有个对https的支持没启用的话 注释掉</p>
<hr>
<p>自从spark2.0.0发布之后，每次启动hive的时候，总会发现一个小问题，启动 hive –service metastore的时候，会报一个小BUG: 无法访问/lib/spark-assembly-<em>.jar<br><img src="https://ws1.sinaimg.cn/large/006tNc79ly1fqex19hd8jj30nm02tt8o.jpg" alt=""><br>分析其源码架构，发现主要原因是：在/bin/hive文件中，有这样的命令：加载spark中相关的JAR包。<br><img src="https://ws1.sinaimg.cn/large/006tNc79ly1fqex1dwnb4j30ir0410sq.jpg" alt=""><br>但是spark升级到spark2以后，原有lib目录下的大JAR包被分散成多个小JAR包，原来的spark-assembly-</em>.jar已经不存在，所以hive没有办法找到这个JAR包。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; show tables;</span><br><span class="line">OK</span><br><span class="line">Failed with exceptionjava.io.IOException:java.lang.IllegalArgumentException:java.net.URISyntaxException: Relative path in absolute URI:$&#123;system:user.name&#125;</span><br><span class="line">Time taken: 0.193 seconds</span><br></pre></td></tr></table></figure>
<p>解决办法：把下列system:删除</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hive.exec.local.scratchdir</span><br><span class="line">$&#123;system:java.io.tmpdir&#125;/$&#123; system:user.name&#125;</span><br><span class="line">Localscratch space for Hive jobs</span><br></pre></td></tr></table></figure>
<p>变成</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hive.exec.local.scratchdir</span><br><span class="line">$&#123;java.io.tmpdir&#125;/$&#123; user.name&#125;</span><br><span class="line">Localscratch space for Hive jobs</span><br></pre></td></tr></table></figure>
<hr>

        
      
    </div>

    

    

  </article>

    
      
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          <a class="post-link" href="/2018/04/11/项目总结-水环境管理系统/">项目总结-水环境管理系统</a>
        
      </h1>

      <div class="post-meta">
        <span class="post-time">
          2018-04-11
        </span>
        
        
      </div>
    </header>

    
    

    <div class="post-content">
      
        
        

        
          <h2 id="待更新"><a href="#待更新" class="headerlink" title="待更新"></a>待更新</h2>
        
      
    </div>

    

    

  </article>

    
      
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          <a class="post-link" href="/2018/04/11/项目总结-BI系统/">项目总结-BI系统</a>
        
      </h1>

      <div class="post-meta">
        <span class="post-time">
          2018-04-11
        </span>
        
        
      </div>
    </header>

    
    

    <div class="post-content">
      
        
        

        
          <h2 id="待更新"><a href="#待更新" class="headerlink" title="待更新"></a>待更新</h2>
        
      
    </div>

    

    

  </article>

    
  </section>

  
  <nav class="pagination">
    
    
      <a class="next" href="/page/2/">
        <span class="next-text">下一页</span>
        <i class="iconfont icon-right"></i>
      </a>
    
  </nav>


          </div>
          

        </div>
      </main>

      <footer id="footer" class="footer">

  <div class="social-links">
    
      
        
          <a href="mailto:pekeyli@qq.com" class="iconfont icon-email" title="email"></a>
        
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
        
          <a href="/PekeyLi" class="iconfont icon-weibo" title="weibo"></a>
        
      
    
      
    
      
    
      
    
      
    
      
    
    
    
      
      <a href="/atom.xml" class="iconfont icon-rss" title="rss"></a>
    
  </div>


<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://hexo.io/">Hexo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/ahonn/hexo-theme-even">Even</a>
  </span>

  <span class="copyright-year">
    
    &copy; 
     
      2015 - 
    
    2018

    <span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">Pekey Li</span>
  </span>
</div>

      </footer>

      <div class="back-to-top" id="back-to-top">
        <i class="iconfont icon-up"></i>
      </div>
    </div>

    


    




  
    <script type="text/javascript" src="/lib/jquery/jquery-3.1.1.min.js"></script>
  

  
    <script type="text/javascript" src="/lib/slideout/slideout.js"></script>
  

  


    <script type="text/javascript" src="/js/src/even.js?v=2.6.0"></script>
<script type="text/javascript" src="/js/src/bootstrap.js?v=2.6.0"></script>

  </body>
</html>
